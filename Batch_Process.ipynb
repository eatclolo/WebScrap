{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loop_Document():\n",
    "    source = './Document/'\n",
    "    Document_List = []\n",
    "    Document_Path_List = []\n",
    "    df = pd.DataFrame.from_dict({'File' : [] , 'Respondent_Roles': [], 'Respondent_Names': [], 'Appellant_Roles': [], 'Appellant_Names': [], 'Claimant_Roles': [], 'Claimant_Names': [], 'Applicant_Roles': [], 'Applicant_Names': [], 'Representation' : [],'Event': [], 'Event_Date': [], 'Translate': [], 'Judgment': [], 'Coram': [], 'Final_Role': [], 'Court': []})\n",
    "    with os.scandir(source) as os_it:\n",
    "        for f_name in os_it:\n",
    "            if f_name.name.endswith(('.html')):\n",
    "                    Document_List.append(f_name.name)\n",
    "    for i in Document_List:\n",
    "        Document_Path = \"./Document/\" + i\n",
    "        Document_Path_List.append(Document_Path)\n",
    "    for i in Document_Path_List:\n",
    "        Result = Inspect_Document(i)\n",
    "        File = {\"File\" : i.replace('./Document/', \"\").replace('.html', \"\")}\n",
    "        Dict = {**File, **Result}\n",
    "        df = df.append(Dict, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inspect_Document(Path):\n",
    "    File = open(Path, \"r\")\n",
    "    try:\n",
    "        Html_code = File.read()\n",
    "        Doc_Soup = BeautifulSoup(Html_code, 'html.parser')\n",
    "        Parties = Extract_Parties(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Parties))\n",
    "        Dates = Extract_Dates(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Dates))\n",
    "        Representation = Extract_Representation(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Representation))\n",
    "        Translate = Extract_Translate(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Translate))\n",
    "        Judgment = Extract_Judgment(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Judgment))\n",
    "        Coram = Extract_Coram(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Coram))\n",
    "        Final_Role = Extract_Final_Role(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Final_Role))\n",
    "        Court = Extract_Court(Doc_Soup)\n",
    "        #print(Path + \": \" + str(Court))\n",
    "        Dict = {**Parties, **Representation, **Dates, **Translate, **Judgment, **Coram, **Final_Role, **Court}\n",
    "        return Dict\n",
    "    except UnicodeDecodeError:\n",
    "        print(Path + \"   UniCode\")\n",
    "        return {'Respondent_Roles': [], 'Respondent_Names': [], 'Appellant_Roles': [], 'Appellant_Names': [], 'Claimant_Roles': [], 'Claimant_Names': [], 'Applicant_Roles': [], 'Applicant_Names': [], 'Representation' : [],'Event': [], 'Event_Date': [], 'Translate': [], 'Judgment': [], 'Coram': [], 'Final_Role': [], 'Court': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Parties(Doc_Soup):\n",
    "    Parties = Doc_Soup.find('parties')\n",
    "    if Parties != None:\n",
    "        Respondent_Tag = Parties.find_all(lambda tag:tag.name==\"td\" and \"Respondent\" in tag.text)\n",
    "        Respondent_Roles = []\n",
    "        Respondent_Names = []\n",
    "        for i in Respondent_Tag:\n",
    "            Respondent_Roles.append(i.text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))\n",
    "            Respondent_Names.append(i.find_previous('td').text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))\n",
    "        Appellant_Tag = Parties.find_all(lambda tag:tag.name==\"td\" and \"Appellant\" in tag.text)\n",
    "        Appellant_Roles = []\n",
    "        Appellant_Names = []\n",
    "        for i in Appellant_Tag:\n",
    "            Appellant_Roles.append(i.text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))\n",
    "            Appellant_Names.append(i.find_previous('td').text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))\n",
    "        Claimant_Tag = Parties.find_all(lambda tag:tag.name==\"td\" and \"Claimant\" in tag.text)\n",
    "        Claimant_Roles = []\n",
    "        Claimant_Names = []\n",
    "        for i in Claimant_Tag:\n",
    "            Claimant_Roles.append(i.text)\n",
    "            Claimant_Names.append(i.find_previous('td').text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))\n",
    "        Applicant_Tag = Parties.find_all(lambda tag:tag.name==\"td\" and \"Applicant\" in tag.text)\n",
    "        Applicant_Roles = []\n",
    "        Applicant_Names = []\n",
    "        for i in Applicant_Tag:\n",
    "            Applicant_Roles.append(i.text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))\n",
    "            Applicant_Names.append(i.find_previous('td').text.strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"  \", \" \"))   \n",
    "        return {\"Respondent_Roles\" : Respondent_Roles, \"Respondent_Names\" : Respondent_Names, \"Appellant_Roles\" : Appellant_Roles, \"Appellant_Names\" : Appellant_Names,  \"Claimant_Roles\" : Claimant_Roles, \"Claimant_Names\" : Claimant_Names, \"Applicant_Roles\" : Applicant_Roles, \"Applicant_Names\" : Applicant_Names}\n",
    "    return {\"Respondent_Roles\" : ['empty (no tag)'], \"Respondent_Names\" : ['empty (no tag)'], \"Appellant_Roles\" : ['empty (no tag)'], \"Appellant_Names\" : ['empty (no tag)'],  \"Claimant_Roles\" : ['empty (no tag)'], \"Claimant_Names\" : ['empty (no tag)'], \"Applicant_Roles\" : ['empty (no tag)'], \"Applicant_Names\" : ['empty (no tag)']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Dates(Doc_Soup):\n",
    "    Dates_Tag = Doc_Soup.find(lambda tag:tag.name==\"date\")\n",
    "    if Dates_Tag != None:\n",
    "        Initial_Search = Dates_Tag.find_all('td', text = re.compile(\"^Date.*\\:|：\"))\n",
    "        Event = []\n",
    "        Event_Date = []\n",
    "        if Initial_Search == []:\n",
    "            Advance_Search = Dates_Tag.find_all('p', text = re.compile(\"(^Date.*\\:|：)\"))\n",
    "            if Advance_Search == []:\n",
    "                Dates = {\"Event\" : 'empty', \"Event_Date\" : 'empty'}\n",
    "                return Dates\n",
    "            for i in Advance_Search:\n",
    "                Event_Pattern = r\"(Date.*\\:)\"\n",
    "                Event_Search = re.search(Event_Pattern, str(i))\n",
    "                if Event_Search != None:\n",
    "                    Event.append(Event_Search.group().strip())\n",
    "                    Event_Date.append(i.string.replace(Event_Search.group().strip(),\"\").strip())\n",
    "                else:\n",
    "                    Event = ['empty']\n",
    "                    Event_Date = ['empty']\n",
    "        else:\n",
    "            Final_Search = Dates_Tag.find_all('td', attrs={'class' : 'auto-style1'})\n",
    "            if Final_Search == []:\n",
    "                Extra_Search = Dates_Tag.find_all('td', attrs={'valign' : 'top'})\n",
    "                if Extra_Search == []:\n",
    "                    for i in Initial_Search:\n",
    "                        Event.append(i.text.strip())\n",
    "                        Event_Date.append(i.find_next('td').text.strip())\n",
    "                else:\n",
    "                    for i in Extra_Search:\n",
    "                        Event_Pattern = r\"(Date.*\\:)\"\n",
    "                        Event_Search = re.search(Event_Pattern, str(i))\n",
    "                        if Event_Search != None:\n",
    "                            Event.append(Event_Search.group().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace('amp;', \"\"))\n",
    "                            Event_Date.append(i.text.replace(Event_Search.group().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace('amp;', \"\"),\"\").strip())\n",
    "                        else: \n",
    "                            Event = ['empty']\n",
    "                            Event_Date = ['empty']    \n",
    "            else:\n",
    "                for i in Final_Search:\n",
    "                    Event_Pattern = r\"(Date.*\\:)\"\n",
    "                    Event_Search = re.search(Event_Pattern, str(i))\n",
    "                    if Event_Search != None:\n",
    "                        Event.append(Event_Search.group().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace('amp;', \"\"))\n",
    "                        Event_Date.append(i.text.replace(Event_Search.group().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace('amp;', \"\"),\"\").strip())\n",
    "                    else: \n",
    "                        Event = ['empty']\n",
    "                        Event_Date = ['empty']\n",
    "        Dates = {\"Event\" : Event, \"Event_Date\" : Event_Date}\n",
    "    else:\n",
    "        Dates = {\"Event\" : 'empty (no tag)', \"Event_Date\" : 'empty (no tag)'}\n",
    "    return Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Representation(Doc_Soup):\n",
    "    Representation_Tag = Doc_Soup.find('representation')\n",
    "    Representation_List = []\n",
    "    if Representation_Tag != None:\n",
    "        Initial_Search = Representation_Tag.find_all('p')\n",
    "        if Initial_Search != []:\n",
    "            for i in Initial_Search:\n",
    "                if '\\xa0' not in i.text:\n",
    "                    Representation_List.append(i.text.strip().replace('\\n', \" \"))\n",
    "        else:\n",
    "            Advance_Search = Representation_Tag.find_all('td')\n",
    "            if Advance_Search != []:\n",
    "                for i in Advance_Search:\n",
    "                    Representation_List.append(i.text.strip())\n",
    "            else:\n",
    "                Representation = {'Representation' : ['empty']}\n",
    "                return Representation\n",
    "        Representation = {\"Representation\" : Representation_List}\n",
    "    else:\n",
    "        Representation = {'Representation' : ['empty']}\n",
    "    return Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Translate(Doc_Soup):\n",
    "    Translate_Tag = Doc_Soup.find('p', text = re.compile(\"^Translated\"))\n",
    "    if Translate_Tag != None:\n",
    "        Translate_Tag = Doc_Soup.find('p', text = re.compile(\"^Translated\")).text.strip()\n",
    "    else:\n",
    "        Translate_Tag = Doc_Soup.find('p', text = re.compile(\"\\b*Vetted\"))\n",
    "        if Translate_Tag == None:\n",
    "            Translate = {'Translate' : ['empty']}\n",
    "            return Translate\n",
    "        else:\n",
    "            Translate_Tag = Doc_Soup.find('p', text = re.compile(\"\\b*Vetted\")).text.strip()\n",
    "    Translate = {\"Translate\" : [Translate_Tag]}\n",
    "    return Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Judgment(Doc_Soup):\n",
    "    Representation_Tag = Doc_Soup.find('representation')\n",
    "    if Representation_Tag != None:\n",
    "        Judgment_Tag = Representation_Tag.find_previous('p', attrs = {\"class\" : \"heading\"}, text = re.compile(\"\\b*Judgment\"))\n",
    "        if Judgment_Tag != None:\n",
    "            Judgment_Info = Representation_Tag.find_previous('p', attrs = {\"class\" : \"heading\"}, text = re.compile(\"\\b*Judgment\")).find_next('p').text.strip().replace('\\xa0', \" \")\n",
    "            Judgment = {\"Judgment\" : [Judgment_Info]}\n",
    "        else:\n",
    "            Judgment = {'Judgment' : ['empty']}\n",
    "    else:\n",
    "        Judgment = {'Judgment' : ['empty (no Tag)']}\n",
    "    return Judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Coram(Doc_Soup):\n",
    "    Coram_Tag = Doc_Soup.find('coram')\n",
    "    if Coram_Tag != None:\n",
    "        Initial_Search = Coram_Tag.find('td', text = re.compile(\"^Before.*\\:\"))\n",
    "        if Initial_Search != None:\n",
    "            #Coram_Info = Initial_Search.find_next('td').text.strip().replace('\\xa0', \"\").replace('\\n', \" \")\n",
    "            Search = Coram_Info = Coram_Tag.get_text().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"Before: \", \"\").replace(\"  \", \" \").strip()\n",
    "            Coram = {'Coram' : [Coram_Info]}\n",
    "        else:\n",
    "            Advance_Search = Coram_Tag.find('p', text = re.compile(\"(^Before:\\s.*)\"))\n",
    "            if Advance_Search != None:\n",
    "                Coram_Info = Advance_Search.get_text().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"Before: \", \"\").replace(\"  \", \" \").strip()\n",
    "                Coram = {'Coram' : [Coram_Info]}\n",
    "            else: \n",
    "                Coram_Info = Coram_Tag.get_text().strip().replace('\\n', \" \").replace('\\xa0', \"\").replace(\"Before: \", \"\").replace(\"  \", \" \").strip()\n",
    "                Coram = {'Coram' : [Coram_Info]}\n",
    "    else:\n",
    "        Coram = {'Coram' : ['empty']}\n",
    "    return Coram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Final_Role(Doc_Soup):\n",
    "    Representation_Tag = Doc_Soup.find('representation')\n",
    "    if Representation_Tag != None:\n",
    "        Final_Role_Table_Tag = Representation_Tag.find_previous('table')\n",
    "        if Final_Role_Table_Tag != None:\n",
    "            Final_Role_Info = Final_Role_Table_Tag.get_text()\n",
    "            Rows = Final_Role_Table_Tag.find_all('tr')\n",
    "            data = []\n",
    "            for row in Rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [ele.get_text().strip().replace('\\n', \"\").replace('_', \"\").replace('\\xa0', \"\").replace(\"  \", \"\") for ele in cols]\n",
    "                data.append([ele for ele in cols])\n",
    "            Final_Role = {'Final_Role' : [data]}\n",
    "        else:\n",
    "            Final_Role = {'Final_Role' : ['empty']}\n",
    "    else:\n",
    "        Final_Role = {'Final_Role' : ['empty (no tag)']}\n",
    "    return Final_Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Court(Doc_Soup):\n",
    "    Center_Tag = Doc_Soup.find_all('p', attrs = {'style' : 'text-align:center'}, limit = 3)\n",
    "    Court_Info = \"\"\n",
    "    if Center_Tag != None:\n",
    "        for i in Center_Tag:\n",
    "            Court_Info += i.text.strip().replace('\\n', \" \").replace('\\xa0', \"\")\n",
    "        Court = {'Court' : [Court_Info]}\n",
    "    else:\n",
    "        Court = {'Court' : ['empty']}\n",
    "    return Court"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = Loop_Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_csv('Batch_Process.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}